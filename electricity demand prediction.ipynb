{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport random\nimport datetime\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8554ee0e7c1eb0c1da5f999c2d2613cbbfe1e38e"
      },
      "cell_type": "code",
      "source": "from tqdm import tqdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "**PREPARING THE WEATHER DATA**\n"
    },
    {
      "metadata": {
        "_uuid": "3329364c14188491803a1eab7b323986cc9db5c0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "def prepare_weather (weather1):\n    weather1 =weather1.drop(['Data Quality' ,'Max Temp Flag', 'Min Temp Flag',\n                             'Mean Temp Flag', 'Heat Deg Days Flag' ,\n                             'Cool Deg Days Flag', 'Total Rain (mm)',\n                             'Total Precip Flag' , 'Total Snow (cm)' ,\n                             'Snow on Grnd Flag', 'Dir of Max Gust Flag',\n                             'Spd of Max Gust Flag','Total Rain Flag',\n                             'Dir of Max Gust (10s deg)', 'Total Snow Flag'] , axis = 1)\n    \n    weather1 = weather1.drop(weather1.columns[7] , axis=1)\n    weather1 = weather1.drop(weather1.columns[7] , axis=1)\n    year = weather1.iloc[: , 1].values\n    weather1 = weather1.drop(weather1.columns[1] , axis=1)\n    weather1 = weather1.drop(weather1.columns[0] , axis=1)\n    \n    weather1.iloc[: , 2] = (weather1.iloc[:,2]) + 273\n    weather1.iloc[: , 3] = (weather1.iloc[:,3]) + 273\n    weather1.iloc[: , 4] = (weather1.iloc[:,4]) + 273\n    \n    weather1.iloc[:,6].fillna(0 , inplace = True)\n    weather1.iloc[:,2].fillna(method ='pad' ,limit = 18, inplace = True)\n    weather1.iloc[:,3].fillna(method ='pad' ,limit = 16, inplace = True)\n    weather1.iloc[:,4].fillna(method ='pad' ,limit = 18, inplace = True)\n    weather1.iloc[:,5].fillna(0 , inplace = True)\n    weather1.iloc[:,7].fillna('<31' , inplace = True)\n    weather1[weather1.columns[7]][weather1[weather1.columns[7]] == '<31']  = np.random.randint(1 , 30, len(weather1[weather1.columns[7]][weather1[weather1.columns[7]] == '<31']))\n    weather1['Year'] = year\n    return weather1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "432ea30c1eb5a7bdff409ac2b501c1fab700cb6f"
      },
      "cell_type": "code",
      "source": "weather = pd.read_excel('../input/ontario electricity and weather data/weather data 2012-2018.xlsx')\nweather = prepare_weather(weather)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c0be9a49671a53ec47c7b5e0a17983fa280c8ad"
      },
      "cell_type": "code",
      "source": "print(weather.isna().sum())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1eb6d7ea9303246e6b659d65cf8196ea11c22b75"
      },
      "cell_type": "markdown",
      "source": "**PREPARING THE ELECTRICITY PRICE IN ONTARIO DATA**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9aafb61312d39f6c6015306e58d388651bbf9cdd"
      },
      "cell_type": "code",
      "source": "def dow(date):\n    days=[\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n    dayNumber=date.weekday()\n    return days[dayNumber]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "18add93c49c2f27fb181c0ee8c8f3df153635752"
      },
      "cell_type": "code",
      "source": "def preprocess_price(price1):\n    price1 = price1.drop('Hour' , axis =1)\n    price1 = price1.groupby('Date').max()\n    ind = np.arange(0 , len(price1))\n    price1['Date'] = price1.index\n    price1.index = ind\n    for i in range(len(price1)): \n       price1.loc[i,'Day'] = int(price1.loc[i,'Date'].split('-')[0])    \n       price1.loc[i,'Month'] = int(price1.loc[i,'Date'].split('-')[1])    \n       price1.loc[i,'Year'] = int(price1.loc[i,'Date'].split('-')[2])    \n       price1.loc[i , 'weekday'] = dow(datetime.date(int(price1.loc[i,'Year']) , int(price1.loc[i,'Month']) , int(price1.loc[i,'Day'])))\n    price1 = price1.drop('Date' , axis =1)\n    price1.drop\n    return price1\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9d9f0f5c0b30bdc8286202df1af0a05521156825"
      },
      "cell_type": "code",
      "source": "price1 = pd.read_csv('../input/ontario electricity and weather data/nodal price 2015.csv')\nprice1 = preprocess_price(price1)\nprice2 = pd.read_csv('../input/ontario electricity and weather data/nodal price 2016.csv')\nprice2 = preprocess_price(price2)\nprice3 = pd.read_csv('../input/ontario electricity and weather data/nodal price 2017.csv')\nprice3 = preprocess_price(price3)\nprice4 = pd.read_csv('../input/ontario electricity and weather data/nodal price 2018.csv')\nprice4 = preprocess_price(price4)\nprice5 = pd.read_csv('../input/ontario electricity and weather data/nodal price 2012.csv')\nprice5 = preprocess_price(price5)\nprice6 = pd.read_csv('../input/ontario electricity and weather data/nodal price 2013.csv')\nprice6 = preprocess_price(price6)\nprice7 = pd.read_csv('../input/ontario electricity and weather data/nodal price 2014.csv')\nprice7 = preprocess_price(price7)\nframes = [price1 , price2 , price3, price4 , price5 , price6 , price7]\nprice = pd.concat(frames)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9663cc83d17e83cae35f490bc949af7b209cb093"
      },
      "cell_type": "code",
      "source": "price1 = pd.read_csv('../input/ontario electricity and weather data/elec_price_2012.csv')\nprice1 = preprocess_price(price1)\nprice2 = pd.read_csv('../input/ontario electricity and weather data/elec_price_2013.csv')\nprice2 = preprocess_price(price2)\nprice3 = pd.read_csv('../input/ontario electricity and weather data/elec_price_2014.csv')\nprice3 = preprocess_price(price3)\nprice4 = pd.read_csv('../input/ontario electricity and weather data/elec_price_2015.csv')\nprice4 = preprocess_price(price4)\nprice5 = pd.read_csv('../input/ontario electricity and weather data/elec_price_2016.csv')\nprice5 = preprocess_price(price5)\nprice6 = pd.read_csv('../input/ontario electricity and weather data/elec_price_2017.csv')\nprice6 = preprocess_price(price6)\nprice7 = pd.read_csv('../input/ontario electricity and weather data/elec_price_2018.csv')\nprice7 = preprocess_price(price7)\nframes = [price1 , price2 , price3, price4 , price5 , price6 , price7]\nhoep_price = pd.concat(frames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4195ad9197dddb160e2590b830a8dc4cdb62d6f9"
      },
      "cell_type": "code",
      "source": "print(hoep_price.dtypes)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bc53ec897268c37eaa2cddd51c77981c2fb1d054"
      },
      "cell_type": "code",
      "source": "hoep_price['HOEP'] = pd.to_numeric(hoep_price['HOEP'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b349d6b93e8e02253167905e30135d14d24c817"
      },
      "cell_type": "code",
      "source": "hoep_price.dtypes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6ec4f79c41bdbc43efe4f23e994b6c122a033a7e"
      },
      "cell_type": "markdown",
      "source": "**PREPARING THE ONTARIO DEMAND DATA**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d68649f22fb948ae6f912fb7a37f2d5cd93dc614"
      },
      "cell_type": "code",
      "source": "price1 = pd.read_csv('../input/ontario electricity and weather data/demand 2012.csv')\nprice1 = preprocess_price(price1)\nprice2 = pd.read_csv('../input/ontario electricity and weather data/demand 2013.csv')\nprice2 = preprocess_price(price2)\nprice3 = pd.read_csv('../input/ontario electricity and weather data/demand 2014.csv')\nprice3 = preprocess_price(price3)\nprice4 = pd.read_csv('../input/ontario electricity and weather data/demand 2015.csv')\nprice4 = preprocess_price(price4)\nprice5 = pd.read_csv('../input/ontario electricity and weather data/demand 2016.csv')\nprice5 = preprocess_price(price5)\nprice6 = pd.read_csv('../input/ontario electricity and weather data/demand 2017.csv')\nprice6 = preprocess_price(price6)\nprice7 = pd.read_csv('../input/ontario electricity and weather data/demand 2018.csv')\nprice7 = preprocess_price(price7)\nframes = [price1 , price2 , price3, price4 , price5 , price6 , price7]\ndemand = pd.concat(frames)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57b1128e23ffb3b017d232e7351d4c3496b2ee56"
      },
      "cell_type": "code",
      "source": "demand['Ontario Demand'].hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4560c44d34e4b26287507206db34141c8a80930d"
      },
      "cell_type": "markdown",
      "source": "As we can see that the demand data is slightly positiveli skewed, Hence taking of log of demand data to unskew the data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e6e53190722478521b5022594b8a40e0c71700b"
      },
      "cell_type": "code",
      "source": "from math import log\ndem = demand['Ontario Demand']\ndem = np.array(dem).reshape((len(dem) , 1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d09cb0a8bcdfbc85c23683e6b601b6518241cee"
      },
      "cell_type": "code",
      "source": "dem = np.log10(dem)\ndemand['Ontario Demand'] = dem",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de43f0b309dbb092843012094ac22bb7a5c6c50d"
      },
      "cell_type": "code",
      "source": "demand['Ontario Demand'].hist()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dfd34206637f46963e239ff1c6618b08dc68e9b0"
      },
      "cell_type": "markdown",
      "source": "**COMBINING ALL DATA TO MAKE THE FINAL DATA SET**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "88851137f4341c7d15a6bd109c27fc76fa39e515"
      },
      "cell_type": "code",
      "source": "price_demand_combined = pd.merge(price,hoep_price , on = ['Day' , 'Month' ,'Year', 'weekday'])\ndataset = pd.merge(price_demand_combined , weather , on = ['Day' , 'Month' , 'Year'] )\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cbd6e25b290fdf844ac4dd1612d307a1a1d603f1"
      },
      "cell_type": "code",
      "source": "dataset = pd.merge(dataset , demand , on = ['Day' , 'Month' , 'Year' , 'weekday'])\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f02a346277b821ae1112308c4911bdb28256f6f7"
      },
      "cell_type": "markdown",
      "source": "**NOW ANALYZING AND STUDYING THE DATA**\n**FINDING TRENDS AND CORRELATION BETWEEN FEATURES AND DEPENDENT VARIABLES**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "91c968ef00ce9e765c1f08f3b854fbc3659928d9"
      },
      "cell_type": "code",
      "source": "dataset.columns = ['nodal price' , 'Day' , 'Month' ,'Year' \n                                          ,'weekday','hoep','max temp' , 'min temp',\n                                         'mean temp' , 'precipitation','snow', 'wind speed' , \n                                         'ontario demand']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1887ba7f529bd2d7a88fad37205012b5b37842d8"
      },
      "cell_type": "code",
      "source": "dataset['wind speed'] = pd.to_numeric(dataset['wind speed'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "23699ee31a975a3a7be4bb31a29a6ef88f5ba1a6"
      },
      "cell_type": "code",
      "source": "print(dataset[['weekday' , 'ontario demand']].groupby(['weekday']).mean())\nplt.plot(dataset[['weekday' , 'ontario demand']].groupby(['weekday']).mean())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d4741b98fdbafdea06d0c684efe380f624083ef1"
      },
      "cell_type": "markdown",
      "source": "AS WE CAN OBSEERVE THE DEMAND IS HIGH SURING WRKING DAYS AND REDUCES AS WE APPROACH THE WEEKEND"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07988a606088b72c6c3e775062a6b675ddbcbb34"
      },
      "cell_type": "code",
      "source": "print(dataset[['Month' , 'ontario demand']].groupby(['Month']).mean())\nplt.plot(dataset[['Month' , 'ontario demand']].groupby(['Month']).mean() )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7677be79c8c1cf2084eb357d7b17a210c5246bf7"
      },
      "cell_type": "markdown",
      "source": "**AS WE CAN SEE THE DEMANDS ARE LOWEST DURING THE APRIL T0 JUNE, AND HIGHEST IN JAN , FEB JULY AND AUG**"
    },
    {
      "metadata": {
        "_uuid": "4ce849901902cc6e1dd9ff79f4d715a39fb3dc7f"
      },
      "cell_type": "markdown",
      "source": "**seasons in ontario canada**\n1. dec - feb  -> winter  (high demands)\n2. march - june -> spring (low demands)\n3. july - sept -> summer  (high demands)\n4. oct - dec -> autumn ( moderate demands)\n\n\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5a33bf4a8ef85545cc8aa6b5640f1448a73988f1"
      },
      "cell_type": "code",
      "source": "print(dataset[['Year' , 'ontario demand']].groupby(['Year']).mean())\nplt.plot(dataset[['Year' , 'ontario demand']].groupby(['Year']).mean() )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a31e176b996328c94c4ac0ef93a0a65fbbc91e1c"
      },
      "cell_type": "markdown",
      "source": "**NOW DEALING WITH THE CONTINUOUS FEATURES LIKE TEMP AND WIND SPEED**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a317fc979d42e1331fb0338d8eafc8f8944472bf"
      },
      "cell_type": "code",
      "source": "dataset.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b942dbbd4481dcd83d02205d92b88acbc4df3d95"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nsc_temp = StandardScaler()\ndataset.iloc[: , 6:9] = sc_temp.fit_transform(dataset.iloc[: , 6:9])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e721f66a3a7f5ae060d56fa8ab206d3029055aa8"
      },
      "cell_type": "code",
      "source": "sc_wind = StandardScaler()\ndataset.iloc[: , 11:12] = sc_wind.fit_transform(dataset.iloc[: , 11:12])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ef041c1c1916ddcb8c45b6589ee272a687331f08"
      },
      "cell_type": "code",
      "source": "sc_price = StandardScaler()\ndataset.iloc[: , [0,5]] = sc_price.fit_transform(dataset.iloc[: , [0,5]])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d8b3876297103e2772d360bc4123da8c9a0a5891"
      },
      "cell_type": "markdown",
      "source": "**performing PCA on continuous features**"
    },
    {
      "metadata": {
        "_uuid": "ac63f44416e1a2202b6cad9c140e9a6438c657a7"
      },
      "cell_type": "markdown",
      "source": "PROCESSING TEMPERATURE DATA"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f73ad9047744979aef8c5f6c8ee65a1c6d842186"
      },
      "cell_type": "code",
      "source": "from sklearn.decomposition import PCA\nPca_temp = PCA(n_components = 2)\nfinal = Pca_temp.fit_transform(dataset.iloc[: , 6:9])\nexplained_variance = Pca_temp.explained_variance_ratio_",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5a3d3ae3d8ebcee4614332598c68196d131e7fe"
      },
      "cell_type": "code",
      "source": "explained_variance",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "460de33e67fd79868e2417c3223907e9eb8fd36d"
      },
      "cell_type": "code",
      "source": "dataset = dataset.drop('max temp' , axis =1)\ndataset = dataset.drop('min temp' , axis =1)\ndataset = dataset.drop('mean temp' , axis =1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "67dcd76b91e4f74502452a473fd0cd6958ab62ed"
      },
      "cell_type": "code",
      "source": "final[: , 0].shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7aaedce8f9a1cc491f04434536f11602eb4d83d3"
      },
      "cell_type": "code",
      "source": "dataset['temp_1'] = final[: , 0]\ndataset['temp_2'] = final[: , 1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "77e24d5c2ae90979eac299d8f69b04de26a8c344"
      },
      "cell_type": "markdown",
      "source": "PROCESSING PRECIPITATION DATA"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b5a0c78f7e77ea24b57c20721217820cf0a4f94"
      },
      "cell_type": "code",
      "source": "dataset.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "77e96dde3c58eef20ee0016ff118c80ae0b8facf"
      },
      "cell_type": "code",
      "source": "for i in range(len(dataset)):\n    if(dataset.iloc[i , 6]  > 3 ):\n        dataset.iloc[i , 6] = 1\n    else:\n        dataset.iloc[i , 6] = 0\n    \n    if( dataset.iloc[i , 7] > 2):\n        dataset.iloc[i , 7] = 1\n    else:\n        dataset.iloc[i , 7] = 0\n            \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e6043d6a3395fb62faded732cd9cf2f105095bc"
      },
      "cell_type": "code",
      "source": "print(dataset[['precipitation' , 'ontario demand']].groupby(['precipitation']).mean())\nplt.plot(dataset[['precipitation' , 'ontario demand']].groupby(['precipitation']).mean() , 'r+')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ec647ba6917b809f44b090d5afa10587696a141e"
      },
      "cell_type": "code",
      "source": "print(dataset[['snow' , 'ontario demand']].groupby(['snow']).mean())\nplt.plot(dataset[['snow' , 'ontario demand']].groupby(['snow']).mean() , 'bo' )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e49e9537750af27611002bb5bd520274fa0186d"
      },
      "cell_type": "code",
      "source": "dataset.drop('precipitation' , axis =1, inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2cddb5e960669ce652b89a89eaecf975f6730ccb"
      },
      "cell_type": "markdown",
      "source": "HENCE WE HAVE OBSERVED THAT, ELECTRICITY REMANDS INCREASE DURING SNOWFALL"
    },
    {
      "metadata": {
        "_uuid": "42ca7ec978444efb76b0afad7f1f41d45a3a28b7"
      },
      "cell_type": "markdown",
      "source": "**ANALYZING THE RESULTING DATA**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95a52b234c6ec5622f78192e90a9ffeb00b4cdde"
      },
      "cell_type": "code",
      "source": "dataset.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1b78be0cc59458f261026b4a7a91d95121ef3be0"
      },
      "cell_type": "code",
      "source": "print(dataset[['Day' , 'ontario demand']].groupby(['Day']).mean())\nplt.plot(dataset[['Day' , 'ontario demand']].groupby(['Day']).mean() )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f9b8342a4a5557cf8a648fbce0be413edd0e3e11"
      },
      "cell_type": "code",
      "source": "dataset.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22e43d3ff566c22b71d6bc55d5b8acf01dd129aa"
      },
      "cell_type": "code",
      "source": "\nseason = np.zeros(len(dataset))\nsummer = [7 , 8]\nwinter = [12 ,1 ,2 ,3]\nautumn = [9 , 10 , 11]\nspring = [4 , 5 , 6]\nfor i in range(len(dataset)):\n    if (dataset.iloc[i , dataset.columns.get_loc('Month')] in winter):\n        season[i] = 1\n    if (dataset.iloc[i , dataset.columns.get_loc('Month')] in spring):\n        season[i] = 2\n    if (dataset.iloc[i , dataset.columns.get_loc('Month')] in summer):\n        season[i] = 3\n    if (dataset.iloc[i , dataset.columns.get_loc('Month')] in autumn):\n        season[i] = 4\n    \n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "32630a2d14b610b288372ebc37b8564a56f44382"
      },
      "cell_type": "code",
      "source": "dataset['season'] = season",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "844bd67060ee9efbfa9954d660430c3caf90bff4"
      },
      "cell_type": "code",
      "source": "print(dataset[['nodal price', 'Day', 'Month', 'Year', 'weekday', 'hoep', 'wind speed', 'ontario demand', 'temp_1', 'temp_2' , 'season']].corr())\nsns.heatmap(dataset[['nodal price', 'Day', 'Month', 'Year', 'weekday', 'hoep', 'wind speed', 'ontario demand', 'temp_1', 'temp_2' , 'season']].corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e8f900101198d7a0ac20f56188aaeb1b222d6287"
      },
      "cell_type": "code",
      "source": "print(dataset[['season' , 'ontario demand']].groupby(['season']).mean())\nplt.plot(dataset[['season' , 'ontario demand']].groupby(['season']).mean() )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de514a13846ba53539aa83a8459b451d9841aebb"
      },
      "cell_type": "code",
      "source": "working_day = np.zeros(len(dataset))\nfor i in range(len(dataset)):\n    if (dataset.iloc[i , dataset.columns.get_loc('weekday')] in ['Saturday' , 'Sunday']):\n        working_day[i] = 1\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7686bdceed5eb0da51ff4b57e3cfe5e5af2bd0c0"
      },
      "cell_type": "code",
      "source": "dataset['working day'] = working_day",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29755781e84da0700ec044c4e2f7cba6a2f9a8f6"
      },
      "cell_type": "code",
      "source": "print(dataset[['working day' , 'ontario demand']].groupby(['working day']).mean())\nplt.plot(dataset[['working day' , 'ontario demand']].groupby(['working day']).mean()  , 'bo')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7d1d87d4225c5006bd43d490e1ee3d7257f8cab"
      },
      "cell_type": "code",
      "source": "dataset.drop('weekday' , axis =1 , inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b80c400d5f872787f305e0f36985aa6eedd7c145"
      },
      "cell_type": "code",
      "source": "dataset.drop(['Month' , 'Day'] , axis = 1 , inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "71aaf2595d4dca34e947da5f69b3ae6129a4c558"
      },
      "cell_type": "code",
      "source": "dataset.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72735243d0187a70b399f5b96d77b9ff9684a951"
      },
      "cell_type": "code",
      "source": "sc_demand = StandardScaler()\ndataset.iloc[: , 5:6] = sc_demand.fit_transform(dataset.iloc[: , 5:6])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ad516de41bd652183e5a3613300a2047346857f0"
      },
      "cell_type": "markdown",
      "source": "**SPLITTING THE TRAINING DATA (2012-2017) AND TEST DATA  (2018)**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "83c8d8e3b593143ce219fef4adda787c02d25796"
      },
      "cell_type": "code",
      "source": "train_data  = dataset[dataset['Year'] != 2018]\ntrain_data.index = np.arange(len(train_data))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "091b66fc8413d0549305cb7e19504a66c342ed6e"
      },
      "cell_type": "code",
      "source": "test_data = dataset[dataset['Year'] == 2018]\ntest_data.index = np.arange(len(test_data))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "daf413d5d73418108b6dfbc4d02d1eb6dc001efc"
      },
      "cell_type": "code",
      "source": "y_train = train_data.iloc[: , 5]\ntrain_data.drop('ontario demand' , axis =1 , inplace = True)\ny_test = test_data.iloc[: , 5]\ntest_data.drop('ontario demand' , axis =1 , inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ec695090287a85a6e3df932c7c4bc9e4f766c55e"
      },
      "cell_type": "code",
      "source": "train_data.drop('Year' , axis =1 , inplace = True)\ntest_data.drop('Year' , axis =1 , inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9408bcb233b5d3e8da889cc03355cb09193346ad"
      },
      "cell_type": "markdown",
      "source": "**-----------------------------now training part begins------------------------**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19fc42d52e947929965e874cbe88a1ecb7dafdc7"
      },
      "cell_type": "markdown",
      "source": "***Using genetic algorithm***"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c9857abc03e814ee47ebab3213f3dd1bf97daa6b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ffabd0103bcc532d5612db9f91c929ecbda7f06"
      },
      "cell_type": "code",
      "source": "\ntrain_set = train_data.groupby(['season' , 'snow' , 'working day']).size().reset_index()\ntrain_set = train_set.iloc[: , :-1]\n\ntrain_data['demand'] = y_train\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cce0b95a07a80f154722757f7e2b7bad95f1e854"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "00b8f7c926e5a26c26609e3bec9a6ad8cc8f3d21"
      },
      "cell_type": "markdown",
      "source": "***Using the gradient descent***"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0c7d984471419b4bf46c43e6a82c2bb8f298d57f"
      },
      "cell_type": "code",
      "source": "def computeCost(X,y,theta):\n    tobesummed = np.power(((X @ theta.T)-y),2)\n    return np.sum(tobesummed)/(2 * len(X))\n                  \n\n#gradient descent\ndef gradientDescent(X,y,theta,iters,alpha):\n    cost = np.zeros(iters)\n    for i in range(iters):\n        theta = theta - (alpha/len(X)) * np.sum(X * (X @ theta.T - y), axis=0)\n        cost[i] = computeCost(X, y, theta)\n    return theta,cost\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75a32cdd19c51908466c86b8bff67843b5129f7a"
      },
      "cell_type": "code",
      "source": "train_data.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6307eea28e968b8671d0ed65dcdfcceba15a6db1"
      },
      "cell_type": "code",
      "source": "weight_set = []\nfor i in range(len(train_set)):\n    part = train_data[train_data['season'] == train_set.iloc[i , 0]][train_data['snow'] == train_set.iloc[i , 1]][train_data['working day'] == train_set.iloc[i , 2]]\n    part.drop( ['season' , 'snow' , 'working day'] , axis =1 , inplace = True)\n    part.index = np.arange(len(part))\n    weights = np.random.rand(1,5)\n    weights , cost = gradientDescent (part.iloc[: , :-1].values , part.iloc[: , -1:].values , weights , 1000 , 0.05 )\n    weight_set.append(weights)\n    \n\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0276b400b850a4d1828d39dfe00d51ff6357a7c"
      },
      "cell_type": "code",
      "source": "test_data.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cc40d619e45218c120025fc224309285ba5fc47a"
      },
      "cell_type": "code",
      "source": "weight_set = np.array(weight_set)\nweight_set = weight_set.reshape((12,5))\ny_pred_grad = []\nfor i in range(len(test_data)):\n    rule_select = train_set[train_set['season'] == test_data.iloc[i , 6]][train_set['snow'] == test_data.iloc[i , 2]][train_set['working day'] == test_data.iloc[i , 7]]\n    index = int(rule_select.index[0])\n    print(index)\n    y_pred_grad.append(np.array(test_data.iloc[0 , :5]).reshape((1 , 5)) @ weight_set[index])\n    \ny_pred_grad = np.array(y_pred_grad)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8664b77bdaba6753528f3482e5b4792a70a9826f"
      },
      "cell_type": "markdown",
      "source": "***trying the BPN***"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e0a643ba75bb78cc5fa5d6efb733f82b505cae1b"
      },
      "cell_type": "code",
      "source": "train_set.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "66da34f153f5d19393daa53cce49f7f6c02d1368"
      },
      "cell_type": "code",
      "source": "import keras\nfrom keras.models import Sequential      # this is used to iinitialise pur neural network\nfrom keras.layers import Dense        # this is used to make the different layers ofour nueral network\nann = []\n\nweight_set = []\nfor i in range(len(train_set)):\n    part = train_data[train_data['season'] == train_set.iloc[i , 0]][train_data['snow'] == train_set.iloc[i , 1]][train_data['working day'] == train_set.iloc[i , 2]]\n    part.drop( ['season' , 'snow' , 'working day'] , axis =1 , inplace = True)\n    part.index = np.arange(len(part))\n    model = Sequential()\n    model.add(Dense(4, input_dim=5, activation='relu'))\n    model.add(Dense(4, activation='relu'))\n    model.add(Dense(1, activation='linear'))\n    model.compile(loss='mse', optimizer='adam')\n    model.fit(part.iloc[: , 0:5].values , part.iloc[: , -1:].values , epochs = 100, verbose=0)\n    ann.append(model)\n    \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "20b4df2f5f7eccded10599607dfdd97784a5e7b2"
      },
      "cell_type": "code",
      "source": "test_data.columns",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "872bacf6fff5512b7f2e33d1afd6e80b807b1e14"
      },
      "cell_type": "code",
      "source": "y_pred_ann = []\nfor i in range(len(test_data)):\n    rule_select = train_set[train_set['season'] == test_data.iloc[i , 6]][train_set['snow'] == test_data.iloc[i , 2]][train_set['working day'] == test_data.iloc[i , -1]]\n    index = int(rule_select.index[0])\n    y_pred_ann.append(   ann[index].predict(np.array(test_data.iloc[0 , :5] ).reshape((1 , 5))) )\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "159be9eeb4ebab86a1b8c60894450a098fb5bfef"
      },
      "cell_type": "code",
      "source": "y_pred_ann = np.array(y_pred_ann)\ny_pred_ann = y_pred_ann.reshape((284 , 1))\n\ny_pred_ann = sc_demand.inverse_transform(y_pred_ann)\ny_test = sc_demand.inverse_transform(y_test)\n\nplt.plot(y_pred_ann[:50] , 'red')\nplt.plot(y_test[:50] , 'blue')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9140627f7c56ea69af3276f8fc273e7b34beaf3a"
      },
      "cell_type": "code",
      "source": "y_pred_grad = y_pred_grad.reshape((284 , 1))\ny_pred_grad = sc_demand.inverse_transform(y_pred_grad)\nplt.plot(y_pred_grad[:50] , 'red')\nplt.plot(y_test[:50] , 'blue')\nplt.show()\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8ff7bb2dc89dd984a9d6d6f7069b13325c2fc564"
      },
      "cell_type": "code",
      "source": "plt.plot(y_pred_grad[:100] , 'red')\nplt.plot(y_test[:100] , 'blue')\nplt.show()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0d7b5b0fb4d8b3f52fcc4f56044c0170ad6c3eba"
      },
      "cell_type": "markdown",
      "source": "**AS we cab observe that gradient descent learning has been able to better predict the demand curve**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b1b1622cfed3153c990e233927c6f447f2a9730"
      },
      "cell_type": "code",
      "source": "from math import floor\nfrom random import random, sample ,choice\nfrom tqdm import tqdm\nfrom numpy.linalg import pinv\nfrom numpy import array, dot, mean\n\n\n\ndef multiple_linear_regression(inputs, outputs):\n    X, Y = np.array(inputs), np.array(outputs)\n    X_t, Y_t = X.transpose(), Y.transpose()\n    coeff = np.dot((pinv((np.dot(X_t, X)))), (np.dot(X_t, Y)))\n    Y_p = np.dot(X, coeff)\n    Y_mean = np.mean(Y)\n    SST = np.array([(i - Y_mean) ** 2 for i in Y]).sum()\n    SSR = np.array([(i - j) ** 2 for i, j in zip(Y, Y_p)]).sum()\n    COD = (1 - (SSR / SST)) * 100.0\n    av_error = (SSR / len(Y))\n    return {'COD': COD, 'coeff': coeff, 'error': av_error}\n\n\ndef check_termination_condition(best_individual , generation_count ,max_generations):\n    if ((best_individual['COD'] >= 96.0)\n            or (generation_count == max_generations)):\n        return True\n    else:\n        return False\n    \n    \ndef create_individual(individual_size):\n    return [random() for i in range(individual_size)]   \n\n\ndef create_population(individual_size, population_size):\n    return [create_individual(individual_size) for i in range(population_size)]\n\ndef get_fitness(individual, inputs ,outputs):\n    predicted_outputs = dot(array(inputs), array(individual))\n    output_mean = mean(outputs)\n    SST = array([(i - output_mean) ** 2 for i in outputs]).sum()\n    SSR = array([(i - j) ** 2 for i, j in zip(outputs, predicted_outputs)]).sum()\n    COD = (1 - (SSR / SST)) * 100.0\n    average_error = (SSR / len(outputs))\n    return {'COD': COD, 'error': average_error, 'coeff': individual}\n\n\ndef evaluate_population(population , inputs , outputs , selection_size , best_individuals_stash):\n    fitness_list = [get_fitness(individual, inputs , outputs)\n                    for individual in tqdm(population)]\n    error_list = sorted(fitness_list, key=lambda i: i['error'])\n    best_individuals = error_list[: selection_size]\n    best_individuals_stash.append(best_individuals[0]['coeff'])\n    print('Error: ', best_individuals[0]['error'],\n          'COD: ', best_individuals[0]['COD'])\n    return best_individuals\n\n\n\ndef crossover(parent_1, parent_2 , individual_size):\n    child = {}\n    loci = [i for i in range(0, individual_size)]\n    loci_1 = sample(loci, floor(0.5*(individual_size)))\n    loci_2 = [i for i in loci if i not in loci_1]\n    chromosome_1 = [[i, parent_1['coeff'][i]] for i in loci_1]\n    chromosome_2 = [[i, parent_2['coeff'][i]] for i in loci_2]\n    child.update({key: value for (key, value) in chromosome_1})\n    child.update({key: value for (key, value) in chromosome_2})\n    return [child[i] for i in loci]\n\n\ndef mutate(individual , individual_size , probability_of_gene_mutating):\n    loci = [i for i in range(0, individual_size)]\n    no_of_genes_mutated = floor(probability_of_gene_mutating*individual_size)\n    loci_to_mutate = sample(loci, no_of_genes_mutated)\n    for locus in loci_to_mutate:\n        gene_transform = choice([-1, 1])\n        change = gene_transform*random()\n        individual[locus] = individual[locus] + change\n    return individual\n\ndef get_new_generation(selected_individuals , population_size , individual_size , probability_of_individual_mutating , probability_of_gene_mutating):\n    parent_pairs = [sample(selected_individuals, 2)\n                    for i in range(population_size)]\n    offspring = [crossover(pair[0], pair[1] , individual_size) for pair in parent_pairs]\n    offspring_indices = [i for i in range(population_size)]\n    offspring_to_mutate = sample(\n        offspring_indices,\n        floor(probability_of_individual_mutating*population_size)\n    )\n    mutated_offspring = [[i, mutate(offspring[i] , individual_size,probability_of_gene_mutating)]\n                         for i in offspring_to_mutate]\n    for child in mutated_offspring:\n        offspring[child[0]] = child[1]\n    return offspring\n\n\ndef genetic_regression(inputs , outputs):\n    print(multiple_linear_regression(inputs , outputs))\n    \n    individual_size = len(inputs[0])\n    population_size = 1000\n    selection_size = floor(0.1*population_size)\n    max_generations = 7\n    probability_of_individual_mutating = 0.1\n    probability_of_gene_mutating = 0.25\n    best_possible = multiple_linear_regression(inputs, outputs)\n    best_individuals_stash = [create_individual(individual_size)]\n    initial_population = create_population(individual_size, 1000)\n    current_population = initial_population\n    termination = False\n    generation_count = 0\n    \n    while termination is False:\n        current_best_individual = get_fitness(best_individuals_stash[-1], inputs ,outputs)\n        print('Generation: ', generation_count)\n        best_individuals = evaluate_population(current_population , inputs , outputs , selection_size, best_individuals_stash)\n        current_population = get_new_generation(best_individuals , population_size , individual_size ,probability_of_individual_mutating , probability_of_gene_mutating)\n        termination = check_termination_condition(current_best_individual , generation_count ,max_generations)\n        generation_count += 1\n    \n    else:\n        print(get_fitness(best_individuals_stash[-1], inputs , outputs))\n    \n    best = get_fitness(best_individuals_stash[-1], inputs , outputs)\n    weight = np.array(best['coeff'])\n    weight = weight.reshape((3,1))\n    return weight",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}